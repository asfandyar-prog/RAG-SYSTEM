{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fcf3bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 115 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,PyMuPDFLoader\n",
    "\n",
    "loader = DirectoryLoader(\"../Single-Source/papers\",glob=\"**/*.pdf\",loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c91ecc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading all  the documents from the directory\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def read_all_docs(directory=\"../Single-Source/papers\"):\n",
    "    \"\"\"Read all the documents from the papers directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir=Path(directory)\n",
    "    pdf_files=list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        try: \n",
    "            loader= PyMuPDFLoader(str(pdf_file))\n",
    "            docs=loader.load()\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"source\"]=pdf_file\n",
    "                doc.metadata[\"file_name\"]=pdf_file.name\n",
    "                all_documents.append(doc)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {pdf_file}: {e}\")\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b0c0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 115 documents\n"
     ]
    }
   ],
   "source": [
    "all_documents=read_all_docs()\n",
    "print(f\"\\nRead {len(all_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc21f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## making chunkings of the documents\n",
    "\n",
    "def make_chunks(document,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"Make chunks of the documents\"\"\" \n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(document)\n",
    "    if chunks:\n",
    "        print(f\"Document split into {len(chunks)} chunks\")\n",
    "        print(f\"First chunk: {chunks[0].page_content}\")\n",
    "        print(f\"Last chunk: {chunks[-1].page_content}\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de399b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document split into 587 chunks\n",
      "First chunk: Emerging Properties in Self-Supervised Vision Transformers\n",
      "Mathilde Caron1,2\n",
      "Hugo Touvron1,3\n",
      "Ishan Misra1\n",
      "Herv´e Jegou1\n",
      "Julien Mairal2\n",
      "Piotr Bojanowski1\n",
      "Armand Joulin1\n",
      "1 Facebook AI Research\n",
      "2 Inria∗\n",
      "3 Sorbonne University\n",
      "Figure 1: Self-attention from a Vision Transformer with 8 × 8 patches trained with no supervision. We look at the self-attention of\n",
      "the [CLS] token on the heads of the last layer. This token is not attached to any label nor supervision. These maps show that the model\n",
      "automatically learns class-speciﬁc features leading to unsupervised object segmentations.\n",
      "Abstract\n",
      "In this paper, we question if self-supervised learning pro-\n",
      "vides new properties to Vision Transformer (ViT) [19] that\n",
      "stand out compared to convolutional networks (convnets).\n",
      "Beyond the fact that adapting self-supervised methods to this\n",
      "architecture works particularly well, we make the follow-\n",
      "ing observations: ﬁrst, self-supervised ViT features contain\n",
      "Last chunk: At the scale of 760M, applying QK norm to Gated DeltaNet improves its loss from 2.814 to 2.809 for\n",
      "pre-training at 8K context length, and from 2.691 to 2.683 for extension fine-tuning at 32K.\n",
      "D\n",
      "Additional Details for Decoding Evaluation\n",
      "For sampling, we set the softmax temperature to 1, and the threshold p for top-p vocabulary to 0.95,\n",
      "following [41].\n",
      "In addition, it is widely known that base models without instruction fine-tuning tend to decode\n",
      "patterns of repetition. To address this problem, we use the standard API for repetition penalty in\n",
      "the HuggingFace toolkit for generation, and set its value to 1.1. This value is recommended by many\n",
      "HuggingFace users, and makes the full attention baseline generate reasonable text, as we have found\n",
      "through manual inspection.\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "chunkss=make_chunks(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c378072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets makes the Embeddings\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from  typing import List,Dict,Any,Tuple\n",
    "import chromadb\n",
    "import uuid\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19e071cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Make the embeddings for the documents\"\"\" \n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name=model_name\n",
    "        self.model=None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\" Load the model\"\"\" \n",
    "        try:\n",
    "            self.model=SentenceTransformer(self.model_name)\n",
    "            print(f\"Model {self.model_name} loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            raise\n",
    "        \n",
    "\n",
    "    def get_embeddings(self,text:List[str]):\n",
    "        \"\"\" \n",
    "        Generate the embeddings for the given text\n",
    "        Args : \n",
    "        texts:List of text strings to embed\n",
    "        returns : \n",
    "        numpy array of embeddings with shape (num_texts,embedding_dim)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not loaded. Please load the model first\")\n",
    "        embeddings=self.model.encode(text,show_progress_bar=True)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49321bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 353.94it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model all-MiniLM-L6-v2 loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1f94f9dc7d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding_manager=EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116b5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
